```{r, echo=FALSE, purl=FALSE, message = FALSE}
library(lubridate)
knitr::opts_chunk$set(results='hide', comment = "#>", purl = FALSE)
```


# Data Manipulation using **`dplyr`**{#dplyr}

> Learning Objectives
>
> * Select columns in a data frame with the **`dplyr`** function `select`.
> * Select rows in a data frame according to filtering conditions with the **`dplyr`** function `filter`.
> * Direct the output of one **`dplyr`** function to the input of another function with the 'pipe' operator `%>%`.
> * Add new columns to a data frame that are functions of existing columns with `mutate`.
> * Understand the split-apply-combine concept for data analysis.
> * Use `summarize`, `group_by`, and `tally` to split a data frame into groups of observations, apply a summary statistics for each group, and then combine the results.

------------

Manipulation of data frames is a common task when you start exploring your data in R and **`dplyr`** is a package for making tabular data manipulation easier. 

> Brief recap: 
> Packages in R are sets of additional functions that let you do more stuff. Functions like `str()` or `data.frame()`, come built into R; packages give you access to more of them. Before you use a package for the first time you need to install it on your machine, and then you should import it in every subsequent R session when you need it.

If you haven't, please install the **`tidyverse`** package. 

```{r, eval=FALSE, purl = FALSE}
install.packages("tidyverse")    
```

**`tidyverse`** is an "umbrella-package" that installs a series of packages useful for data analysis which work together well. Some of them are considered **core** packages (among them **`tidyr`**, **`dplyr`**, **`ggplot2`**), because you are likely to use them in almost every analysis. Other packages, like `lubridate` (to work wiht dates) or `haven` (for SPSS, Stata, and SAS data) that you are likely to use not for every analysis are also installed. 

If you type the following command, it will load the **core** `tidyverse` packages. 

```{r, message = FALSE, purl = FALSE}
library("tidyverse")    ## load the core tidyverse packages, incl. dplyr
```

If you need to use functions from `tidyverse` packages other than the core packages, you will need to load them separately.


## What is **`dplyr`**?

**`dplyr`** is one part of a larger **`tidyverse`** that enables you to work
with data in tidy data formats. "Tidy datasets are easy to manipulate, model and visualise, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table." (From Wickham, H. (2014): Tidy Data https://www.jstatsoft.org/article/view/v059i10)


The package **`dplyr`** provides convenient tools for the most common data manipulation
tasks. It is built to work directly with data frames, with many common tasks
optimized by being written in a compiled language (C++). An additional feature is the
ability to work directly with data stored in an external database. The benefits of
doing this are that the data can be managed natively in a relational database,
queries can be conducted on that database, and only the results of the query are
returned.

This addresses a common problem with R in that all operations are conducted
in-memory and thus the amount of data you can work with is limited by available
memory. The database connections essentially remove that limitation in that you
can have a database of many 100s GB, conduct queries on it directly, and pull
back into R only what you need for analysis.

To learn more about **`dplyr`** after the workshop, you may want to check out the [handy data transformation with **`dplyr`** cheatsheet](https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf).


## Subsetting columns and rows

Let's begin with loading our sample data into a data frame.

We will be working a small subset of the data from the [Stanford Open Policing Project](https://openpolicing.stanford.edu). It contains information about traffic stops for blacks and whites in the state of Mississippi during January 2013 to mid-July of 2016. 

```{r}
stops <- read_csv("data/MS_trafficstops_bw_age.csv")
stops
```

You may have noticed that by using `read_csv` we have generated an object
of class `tbl_df`, also known as a "tibble". Tibble's data
structure is very similar to a data frame. For our purposes the only differences
are that 
* (1) columns of class `character` are never converted into factors,  
* (2) it tries to recognize and `date` types
* (3) the output displays the data type of each column under its name, and 
* (4) it only prints the first few rows of data and only as many columns as fit on one screen. If we wanted to print all columns we can use the print command, and set the `width` parameter to `Inf`. To print the first 6 rows for example we would do this: `print(my_tibble, n=6, width=Inf)`.


To select columns of a
data frame with `dplyr`, use `select()`. The first argument to this function is the data
frame (`stops`), and the subsequent arguments are the columns to keep.

```{r, eval=FALSE, purl = FALSE}
select(stops, police_department, officer_id, driver_race)
```

```{r, results = 'show', purl = FALSE, echo=FALSE}
select(stops, police_department, officer_id, driver_race) %>% head()
```

It is worth knowing that `dplyr` is backed by another package with a number of helper functions, which provide convenient functions to select columns based on their names. For example:

```{r, results = 'show', purl = FALSE, echo=FALSE}
select(stops, starts_with("driver"))
```

Check out the [tidyselect reference](https://tidyselect.r-lib.org/reference/language.html) for more.


To subset rows based on specific criteria, we use `filter()`:

```{r, results='show', purl = FALSE, echo=FALSE}
filter(stops, county_name == "Yazoo")
```

Here are some other ways to subset rows:

- by row number: `slice(stops, 1:3) # rows 1-3`
- rows with highest or lowest values of a variable: 
    - `slice_min(stops, driver_age) # likewise slice_max()`
- random rows: 
    - `slice_sample(stops, n = 5) # number of rows to select`
    - `slice_sample(stops, prop = .0001) # fraction of rows to select`

To sort rows by variables use the `arrange` function:

```{r, results='show'}
arrange(stops, county_name, stop_date)
```


## Pipes

What if you wanted to filter **and** select on the same data? For example, lets find drivers over 85 years and only keep the violation and gender columns. There are three ways to do this: use intermediate steps, nested functions, or pipes.

* Intermediate steps:

With intermediate steps, you essentially create a temporary data frame and use
that as input to the next function. This can clutter up your workspace with lots
of objects. 

```{r, eval=FALSE}
tmp_df <- filter(stops, driver_age > 85)
select(tmp_df, violation, driver_gender)
```

* Nested functions

You can also nest functions (i.e. placce one function inside of another).
This is handy, but can be difficult to read if too many functions are nested as things are evaluated from the inside out.

```{r, eval=FALSE}
select(filter(stops, driver_age > 85), violation, driver_gender)
```

* Pipes!

The last option, called "pipes", is the most recent addition to R. Pipes let you take
the output of one function and send it directly to the next, which is useful
when you need to do many things to the same dataset.  Pipes in R look like
`%>%` and are made available via the `magrittr` package, which is installed automatically with **`dplyr`**. If you use RStudio, you can type the pipe with <kbd>Ctrl</kbd>
+ <kbd>Shift</kbd> + <kbd>M</kbd> if you have a PC or <kbd>Cmd</kbd> + 
<kbd>Shift</kbd> + <kbd>M</kbd> if you have a Mac.

```{r, eval=FALSE, purl = FALSE}
stops %>%
  filter(driver_age > 85) %>%
  select(violation, driver_gender)
```


In the above, we use the pipe to send the `stops` data first through
`filter()` to keep rows where `driver_race` is Black, then through `select()`
to keep only the `officer_id` and `stop_date` columns. Since `%>%` takes
the object on its left and passes it as the first argument to the function on
its right, we don't need to explicitly include it as an argument to the
`filter()` and `select()` functions anymore.

If we wanted to create a new object with this smaller version of the data, we
could do so by assigning it a new name:

```{r, results='show', purl = FALSE}
senior_drivers <- stops %>%
  filter(driver_age > 85) %>%
  select(violation, driver_gender, driver_race)

senior_drivers
```

Note that the final data frame is the leftmost part of this expression.

> <h3>Challenge</h3>
>
>  Using pipes, subset the `stops` data to include stops in Tunica county only and retain the columns `stop_date`, `driver_age`, and `violation`. Bonus: sort the table by driver age.

<!---
```{r, eval=FALSE, purl=FALSE}
## Answer
stops %>% 
  filter(county_name == "Tunica") %>% 
  select(stop_date, driver_age, violation) %>% 
  arrange(driver_age)
```
--->

```{r, eval=FALSE, purl=TRUE, echo=FALSE}
## Pipes Challenge:
##  Using pipes, subset the `stops` data to include stops in 
## Tunica county only and retain the columns `stop_date`, `driver_age`,
## and `violation`. Bonus: sort the table by driver age.
```

## Add new columns

Frequently you'll want to create new columns based on the values in existing columns or. For this we'll use `mutate()`. We can also reassign values to an existing column with that function. 

Be aware that new and edited columns will not permanently be added to the existing data frame -- unless we explicitly save the output.

So here is an example using the `year()` function from the lubrudate package to extract the year of the drivers' birthdate:

```{r, eval=F, purl = FALSE}
library(lubridate)

stops %>% 
  mutate(birth_year = year(driver_birthdate))
```


We can keep adding columns like this:

```{r, eval=F, purl = FALSE}

stops %>% 
  mutate(birth_year = year(driver_birthdate),
         birth_cohort = round(birth_year/10)*10) 

```

We are beginning to see the power of piping. Here is a slightly expanded example, where we select the column `birth_cohort` that we have created and send it to plot:

```{r driver-birth-cohorts, results='show', purl = FALSE, fig.cap='Driver Birth Cohorts'}
stops %>% 
  mutate(birth_year = year(driver_birthdate),
         birth_cohort = round(birth_year/10)*10,
         birth_cohort = factor(birth_cohort)) %>%
    select(birth_cohort) %>% 
    plot()
```


> <h3>Challenge</h3>
>
>  Create a new data frame from the `stops` data that meets the following
>  criteria: contains only the `violation` column for female drivers of age 50 that were stopped on a Sunday. For this add a new column to your data frame called
>  `weekday_of_stop` containing the number of the weekday when the stop occurred. Use the `wday()` function from `lubridate` (Sunday = 1).
> 
> Think about how the commands should be ordered to produce this data frame!

```{r, eval=FALSE, purl=TRUE, echo=FALSE}
## Mutate Challenge:
## Create a new data frame from the `stops` data that meets the following
## criteria: contains only the `violation` column for female drivers of age 50 that were stopped on a Sunday. For this add a new column to your data frame called
## `weekday_of_stop` containing the number of the weekday when the stop occurred. Use the `wday()` function from `lubridate` (Sunday = 1).
## Think about how the commands should be ordered to produce this data frame!
```

<!---
```{r, eval=FALSE, purl=FALSE}
## Answer
stops %>% 
  filter(driver_age == 50 & driver_gender == "female") %>% 
  mutate(wds = wday(ymd(stop_date))) %>% 
  select(violation, wds) %>% 
  filter(wds == 1)
```
--->

## What is split-apply-combine?

Many data analysis tasks can be approached using the *split-apply-combine*
paradigm: split the data into groups, apply some analysis to each group, and
then combine the results. 

```{r split-apply-combine, echo=FALSE, results='asis', out.width='\\textwidth', fig.cap='Split - Apply - Combine'}
knitr::include_graphics('img/split-apply-combine.png')
```


**`dplyr`** makes this possible through the use of the `group_by()` function.

`group_by()` is often used together with `summarize()`, which collapses each
group into a single-row summary of that group. `group_by()` takes as arguments
the column names that contain the **categorical** variables for which you want
to calculate the summary statistics. So to view the mean age for black and white drivers:

```{r, results='show', purl = FALSE}
stops %>%
  group_by(driver_race) %>%
  summarize(mean_age = mean(driver_age, na.rm=TRUE))
```

You can also group by multiple columns:

```{r, results='show', purl = FALSE}
stops %>% 
  group_by(county_name, driver_race) %>%
  summarize(mean_age = mean(driver_age, na.rm=TRUE))
```


If we wanted to remove the line with `NA` we could insert a `filter()` in the chain:

```{r, results='show', purl = FALSE}
stops %>%
  filter(!is.na(driver_race)) %>% 
  group_by(county_name, driver_race) %>%
  summarize(mean_age = mean(driver_age, na.rm=TRUE))
```

Recall that `is.na()` is a function that determines whether something is an `NA`. The `!` symbol negates the result, so weâ€™re asking for everything that is _not_ an `NA`.


Once the data are grouped, you can also summarize multiple variables at the same
time (and not necessarily on the same variable). For instance, we could add a
column indicating the minimum age in each group (i.e. county):

```{r, results='show', purl = FALSE}
stops %>%
  filter(!is.na(driver_race)) %>% 
  group_by(county_name, driver_race) %>%
  summarize(mean_age = mean(driver_age, na.rm=TRUE),
            min_age = min(driver_age, na.rm=TRUE))
```


## Tallying

When working with data, it is also common to want to know the number of
observations found for each factor or combination of factors. For this, **`dplyr`**
provides `tally()`. For example, if we wanted to see how many traffic stops each officer recorded we would do:

```{r, eval=F, purl = FALSE}
stops %>%
  group_by(officer_id) %>%
  tally()
```

We can optionally sort the results in descending order by adding `sort=TRUE`:

```{r, eval=F, purl = FALSE}
stops %>%
  group_by(officer_id) %>%
  tally(sort=TRUE)
```

Here, `tally()` is the action applied to the groups created by `group_by()` and counts the total number of records for each category.

Alternatives:
```{r}
stops %>%
  group_by(officer_id) %>%
  summarize(n = n()) # n() is useful when count is needed for a calculation

stops %>%
  count(officer_id) # count() calls group_by automatically, then tallies
```


> <h3>Challenge</h3>
> 
> Which 5 counties were the ones with the most stops in 2013?
> Hint: use the year() function from lubridate.

<!---
```{r, eval=F, echo=FALSE, purl=FALSE}
## Answer 1
library(lubridate)
stops %>% 
   mutate (stopyear = year(ymd(stop_date))) %>% 
   filter(stopyear == 2013) %>% 
   count(county_name, sort=TRUE) %>% 
   head(5)
```
--->

```{r, eval=FALSE, purl=TRUE, echo=FALSE}
## Tally Challenges:
## Which 5 counties were the ones with the most stops in 2013?
## Hint: use the year() function from lubridate.
```

## Joining two tables

<<<<<<< HEAD
It is not uncommon that we have our data spread out in different tables and need to bring those together for analysis. In this example we will combine the numbers of stops for black and white drivers per county together with the numbers of the black and white total population for these counties. The population data are the estimated values of the 5 year average from the 2011-2015 American Community Survey (ACS):
=======
It is not uncommon that we have our data spread out in different tables and need to bring those together for analysis. In this example we will combine the numbers of stops for black and white drivers per county together with the numbers of the black and white total population for these counties. Toe population data are the estimated values of the 5 year average from the 2011-2015 American Community Survey (ACS):
>>>>>>> 1aab4b954ad0f82372da78447cb5bc64fdc759fe

```{r, results='show'}
MS_bw_pop <- read.csv("data/MS_acs2015_bw.csv")
head(MS_bw_pop)
```

In a first step we will use a prevous `dplyr` command to count all the stops per county.

```{r, results='show'}
stops %>% 
  group_by(county_name) %>% 
  summarise(n_stops = n())
```

We will then pipe this into our next operation where we bring the two tables together. We will use `left_join`, which returns all rows from the left table, and all columns from the left and the right table. As unique ID, which uniquely identifies the corresponding records in each table we use the Names. 

```{r, results='show'}
stops %>% 
  group_by(county_name) %>% 
  summarise(n_stops = n()) %>% 
  left_join(MS_bw_pop, by = c("county_name" = "County")) %>% 
  head()
```


Now we can, for example calculate the percentage of the population that gets stopped in each county.

> <h3>Challenge</h3>
> 
> Which county has the highest (lowest) percentage of stopped drivers?
> Use the snippet from above and pipe into the additional operations
> to do this.

<!---
```{r, eval=F, echo=FALSE, purl=FALSE}
## Answer 
stops %>% 
  group_by(county_name) %>% 
  summarise(n_stops = n()) %>% 
  left_join(MS_bw_pop, by = c("county_name" = "County")) %>% 
  mutate(pct_stopped = n_stops/bw_pop * 100) %>% 
  filter(pct_stopped %in% range(pc_stopped))
```
--->

```{r, eval=FALSE, purl=TRUE, echo=FALSE}
## Join Challenge
## In which county has the highest percentage of stopped drivers?
## Use the snippet from above and pipe into the additional operations
## to do this.
```


`dplyr` join functions are generally equivalent `merge` from the base command, but there are a few advantages: 

* rows are kept in existing order
* much faster
* tells you what keys you're merging by (if you don't supply)
* also work with database tables.

https://groups.google.com/d/msg/manipulatr/OuAPC4VyfIc/Qnt8mDfq0WwJ

See `?dplyr::join` for all the possible joins.


